1. HDFS(Hadoop Distributed FileSystem)
  Hadoop作为一个大数据处理，必然需要一个分布式文件系统。
  
  
2. HDFS的设计目标 
  HDFS是一个分布式文件系统，但也是一个特殊的文件系统，有优点，但并不适合所有场合。
  超大文件的存储:            这里的超大文件，可以是几百TB的大文件。(文件系统的所有元数据都存储在内存中，受到内存大小的限制，不适合小文件存储)
  一次写入、多次读取:        读取一行的响应时间并不重要，重要的是甚至读取整个文件的时间。
  提供高吞吐量，非低延迟     高吞吐量更重要, 不适合于低延迟使用, 写入后也不要修改
  普通商用硬件:              并不需要非常可靠的硬件资源
  
  
3. HDFS的基本概念
  NameNode:
    所有元数据常驻内存(故而有内存限制)
    存在单点问题
    NameNode的更多介绍，详见附二
  DataNode:
    数据文件以block的方式保存(默认64M，可配置), 一个文件至少占用一个block
    DataNode会定时向NameNode发送心跳，并汇报当前block情况。

    
4. 支持的其它文件系统
  Hadoop有一个抽象的文件系统概念，HDFS只是其中的一个实现。
  
  Local       使用本地文件系统
  HFTP        名字叫ftp，实际和ftp毫无关系，通过http协议实现
  HSFTP       同上，通过https实现
  FTP         FTP服务器支持的文件系统
  S3          Amazon S3
  ...
  
  
5. 接口
  5.1 java接口
    Hadoop是用java写的，所以java的接口是最全面的。强烈推荐。
  5.2 Thrift
    为了使用Thrift API，需要运行提供Thrift服务的Java服务器，并以代理的方式访问Hadoop文件系统。
    好处是任何具有Thrift绑定的语言都可以访问HDFS。
    坏处是，中间加了一层代理。
  5.3 C语言
    Hadoop提供了一个libhdfs的C语言库，但接口比较简陋，还是直接使用Java的好。
  5.4 FUSE
    FUSE是一个不错的概念，Hadoop也支持它。
  5.5 HTTP && FTP
    不用多说了，一般用不到，效率也太慢了。
    

6. 数据流
  6.1 文件写入
    1) 客户端向远程的Namenode发起创建文件请求
    2) Namenode会进行合法性检查(是否存在、是否有权限)，成功则生成一条记录，失败会向客户端抛出异常。
    3) 客户端向NameNode申请block。(包括所有replicas的DataNode的地址)
    4) 客户端写入数据是以pipeline形式进行的，client->node1->node2->node3
    5) 最后一个DataNode会返回客户端一个ack，标记写入成功。
    6) 传输过程中，某DataNode出现了故障，NameNode会分配另一个DataNode到pipeline
    7) 客户端通知NameNode写入成功。NameNode对外提供此文件的访问目录。

  6.2 文件读取
    1) 客户端向Namenode发起RPC请求 
    2) Namenode会视情况返回文件的部分或者全部block列表(包括datanode地址)
    3) 客户端会选取最优(最接近)的datanode来读取block 
    4) 读取完当前block的数据后，关闭与当前的datanode连接，并为读取下一个block寻找最佳的datanode 
    5) 当读完列表的block后，继续向Namenode获取下一批block列表。 
    6) 读取完一个block都会进行checksum验证，如果出错，客户端会通知Namenode，然后再尝试另一个datanode


7. 容错处理  
  当有一个datanode挂掉时(不再向namenode发送心跳包), namenode会另选一台合适的机器，将block复制过去。

  
  
  
  
附一: shell命令
  ./hadoop fs -help         -- 查看hdfs命令帮助
  ./hadoop fs -copyFromLocal input/docs/quangle.txt hdfs://localhost/user/tom/quangle.txt     -- 绝对路径
 等同于 ./hadoop fs -copyFromLocal quangle.txt /user/tom/quangle.txt                          -- 相对路径
 等同于 ./hadoop fs -copyFromLocal quangle.txt quangle.txt                                    -- 默认home路径
  ./hadoop fs -copyToLocal quangle.txt quangle.txt
  ./hadoop fs -mkdir books
  ./hadoop fs -ls .
  ./hadoop -chmod a+w /tmp
  ./hadoop fsck /hujj -files -blocks
  

  
附二: NameNode
  1. NameNode主要是维护一些映射关系，包括:
    fileName和block的关系(保存在fsimage, 本地)
    block到mist(机器列表)的关系 (靠心跳维护)
  2. 为了减轻NameNode的压力，其只负责3种交互:
     client访问NameNode获取文件block信息
     DataNode心跳汇报当前block情况。
     SecondaryNameNode做checkpoint
  3. NameNode的目录结构
    ${dfs.name.dir}/current/VERSION
                           /edits         即edits log，尚未合并到fsimage的日志
                           /fsimage       <filename, block>映射关系
                           /fstime        存储check point 的时间

    
drwxrwxr-x 2 hadoop hadoop 4096 06-30 14:30 image
-rw-rw-r-- 1 hadoop hadoop    0 06-18 15:41 in_use.lock
drwxrwxr-x 2 hadoop hadoop 4096 06-30 14:30 previous.checkpoint
[hadoop@master name]$ 

  
  
  
  
http://blog.jeoygin.org/2012/02/hdfs-overview.html

