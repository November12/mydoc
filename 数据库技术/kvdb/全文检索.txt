1. Lucene
Lucene不是一个完整的全文索引应用，而是是一个用Java写的全文索引引擎工具包。它可以方便的嵌入到各种应用中实现针对应用的全文索引/检索功能。
Lucene虽然不支持中文全文索引，但由于Lucene良好架构设计，这个不存在任何问题。
总体上看，Lucene和传统关系型数据库外观上很相似，可以先把Lucene当成一个支持全文索引的数据库系统。

Lucene和关系型数据库比较:

              Lucene 数据库                                                            关系型数据库
1.
索引数据源：doc(field1,field2...) doc(field1,field2...)                  record(field1,field2...) record(field1..)
                         \  indexer /                                                   \  SQL: insert /
                         _____________                                                  _____________
                        | Lucene Index |                                                | DB  Index   |
                        --------------                                                  -------------
                        / searcher \                                                     / SQL: select \
结果输出：Hits(doc(field1,field2) doc(field1...))                     results(record(field1,field2..) record(field1...))
2. 
Document：一个需要进行索引的“单元”                                                Record：记录，包含多个字段
一个Document由多个字段组成 Record：记录，包含多个字段 
3.
            Field：字段                                                                  Field：字段
4.
Hits：查询结果集，由匹配的Document组成                                       RecordSet：查询结果集，由多个Record组成



检索系统来说核心是一个排序问题。
全文索引不是精确匹配，是把最相关的头100条结果满足98%以上用户的需求


Lucene和其它开源全文检索系统的比较:
                  Lucene 数据库                                                            其它开源全文检索系统
1. 增量索引和批量索引    
        可以进行增量的索引(Append)，可以对于大量数据进行批量索引，           只支持批量的索引，有时数据源有一点增加也需要重建索引。
        并且接口设计用于优化批量索引和小批量的增量索引。
2. 数据源
        Lucene没有定义具体的数据源，而是一个文档的结构，                     只针对网页，缺乏其他格式文档的灵活性。
        因此可以非常灵活的适应各种应用
3. 索引内容抓取
        文档是由多个字段组成的，可以指定对具体字段的索引                     只能将文档整个索引
4. 语言分析
        可以扩展分词，搜索相关的内容                                         缺乏通用接口实现
5. 查询分析
        可以制定自己的查询语法规则，如: + - and or
6. 并发访问
        能够支持多用户的使用
        
        
        
        
        
信息检索的过程简介:
1. 构建文本库
  首先要有用户感兴趣的信息(数据), 而文本类型具有可识别，冗余程度低的特点。
  
2. 建立索引
  对文本建立索引，才能被查询到。一般都是采用倒排索引。
  
3. 进行搜索
  用户提出检索请求 -> 分析（预处理) -> 搜索索引 -> 返回信息
  
4. 对结果进行过滤
  对结果进行排序、过滤，再返回。这点直接关系到客户体验，非常重要。
  

  
Lucene 索引
1. 文件类型
命名规则: 前缀名是document数量转成36进制后，在前面加上“_”而构成的

.fnm格式: 包含了document中的所有field的名称。
.fdx格式: 一个索引，用于存储document在.fdt中的位置。
.fdt格式: document真正存储的位置。
.tii格式: .tis的索引文件，它标明了每个.tis文件的词条的位置。
.tis格式: 用于存储分词的词条(Term), 词条可以表示成<field,value>结构, 即field中，包含词value
.cfs格式: 存储复合索引格式。



2. 索引的优化
1. 合并因子mergeFactor
  内存中注入的文档数量
  
2. maxMergeDocs
  索引的合并的最多文档数量
  
3. addindexs() - 使用indexWriter来合并索引
  同时合并多个目录下的索引

4. optimize()
  索引优化采用的策略是建立新的segment来取代那些被合并的segements。(只有合并完成之后，才会删除老的segment，因此短时间内存储空间将是2倍)
  
2. 索引中删除文档
删除只是增加一个标记，并不是物理删除，当optimize的时候，才会真正的删除。(所以，理论上可以反删除操作)
在创建索引的过程中 lucene会为每一个加入索引的document赋予一个id号, 这个id号将唯一的标识每个文档
删除操作写入索引的deletable文件中, 


3. 同步问题
writer.lock
  出现在向索引中添加文档时,或是将文档从索引中删除时,在indexwriter的close()方法被调用时被释放
commit.lock
  主要是与segment合并和读取的操作相关.
  

4. 排序、过滤、分页
1. 相关度排序

2. 使用Sort来排序
  

3. 搜索的过滤器
  搜索时的过滤器
    一种减小搜索范围的方式.同时也可以实现一种安全机制,即保护某些文档无法被检索
    
  分析的过滤

4. 翻页
（1）依赖于session的翻页
  是指将搜索的结果存储于session中，翻页的时候就从session中取出hits集合。(但对内存占用量会很大)
（2）多次查询
  使用完全无状态保持的开发方式，即用户每次翻页，都对索引进行重新检索，然后取得当前页的结果并返回。(效率，已经CPU负荷很大)
（3）缓存＋多次查询
  依靠外部缓存来解决
（4）缓存+多次查询+数据库
  同3
  
5. lucene的分析器
  一个标准的分词器是由两部分组成，一部分是分词器，被称为Tokenizer; 另一部分是过滤器，被称为TokenFilter。
  Tokenizer用于切词，TokenFilter用于去掉一些敏感词、转换大小写、转换单复数等。














        
        

V-Twin搜索引擎(Apple的Copland

